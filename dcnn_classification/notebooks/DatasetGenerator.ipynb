{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for real-time data augmentation on image data.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import io\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from PIL import ImageEnhance\n",
    "    from PIL import Image as pil_image\n",
    "except ImportError:\n",
    "    pil_image = None\n",
    "    ImageEnhance = None\n",
    "\n",
    "\n",
    "if pil_image is not None:\n",
    "    _PIL_INTERPOLATION_METHODS = {\n",
    "        'nearest': pil_image.NEAREST,\n",
    "        'bilinear': pil_image.BILINEAR,\n",
    "        'bicubic': pil_image.BICUBIC,\n",
    "    }\n",
    "    # These methods were only introduced in version 3.4.0 (2016).\n",
    "    if hasattr(pil_image, 'HAMMING'):\n",
    "        _PIL_INTERPOLATION_METHODS['hamming'] = pil_image.HAMMING\n",
    "    if hasattr(pil_image, 'BOX'):\n",
    "        _PIL_INTERPOLATION_METHODS['box'] = pil_image.BOX\n",
    "    # This method is new in version 1.1.3 (2013).\n",
    "    if hasattr(pil_image, 'LANCZOS'):\n",
    "        _PIL_INTERPOLATION_METHODS['lanczos'] = pil_image.LANCZOS\n",
    "\n",
    "\n",
    "def validate_filename(filename, white_list_formats):\n",
    "    \"\"\"Check if a filename refers to a valid file.\n",
    "    # Arguments\n",
    "        filename: String, absolute path to a file\n",
    "        white_list_formats: Set, allowed file extensions\n",
    "    # Returns\n",
    "        A boolean value indicating if the filename is valid or not\n",
    "    \"\"\"\n",
    "    return (filename.lower().endswith(white_list_formats) and\n",
    "            os.path.isfile(filename))\n",
    "\n",
    "\n",
    "def save_img(path,\n",
    "             x,\n",
    "             data_format='channels_last',\n",
    "             file_format=None,\n",
    "             scale=True,\n",
    "             **kwargs):\n",
    "    \"\"\"Saves an image stored as a Numpy array to a path or file object.\n",
    "    # Arguments\n",
    "        path: Path or file object.\n",
    "        x: Numpy array.\n",
    "        data_format: Image data format,\n",
    "            either \"channels_first\" or \"channels_last\".\n",
    "        file_format: Optional file format override. If omitted, the\n",
    "            format to use is determined from the filename extension.\n",
    "            If a file object was used instead of a filename, this\n",
    "            parameter should always be used.\n",
    "        scale: Whether to rescale image values to be within `[0, 255]`.\n",
    "        **kwargs: Additional keyword arguments passed to `PIL.Image.save()`.\n",
    "    \"\"\"\n",
    "    img = array_to_img(x, data_format=data_format, scale=scale)\n",
    "    if img.mode == 'RGBA' and (file_format == 'jpg' or file_format == 'jpeg'):\n",
    "        warnings.warn('The JPG format does not support '\n",
    "                      'RGBA images, converting to RGB.')\n",
    "        img = img.convert('RGB')\n",
    "    img.save(path, format=file_format, **kwargs)\n",
    "\n",
    "\n",
    "def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n",
    "             interpolation='nearest'):\n",
    "    \"\"\"Loads an image into PIL format.\n",
    "    # Arguments\n",
    "        path: Path to image file.\n",
    "        grayscale: DEPRECATED use `color_mode=\"grayscale\"`.\n",
    "        color_mode: The desired image format. One of \"grayscale\", \"rgb\", \"rgba\".\n",
    "            \"grayscale\" supports 8-bit images and 32-bit signed integer images.\n",
    "            Default: \"rgb\".\n",
    "        target_size: Either `None` (default to original size)\n",
    "            or tuple of ints `(img_height, img_width)`.\n",
    "        interpolation: Interpolation method used to resample the image if the\n",
    "            target size is different from that of the loaded image.\n",
    "            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
    "            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
    "            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
    "            \"hamming\" are also supported.\n",
    "            Default: \"nearest\".\n",
    "    # Returns\n",
    "        A PIL Image instance.\n",
    "    # Raises\n",
    "        ImportError: if PIL is not available.\n",
    "        ValueError: if interpolation method is not supported.\n",
    "    \"\"\"\n",
    "    if grayscale is True:\n",
    "        warnings.warn('grayscale is deprecated. Please use '\n",
    "                      'color_mode = \"grayscale\"')\n",
    "        color_mode = 'grayscale'\n",
    "    if pil_image is None:\n",
    "        raise ImportError('Could not import PIL.Image. '\n",
    "                          'The use of `load_img` requires PIL.')\n",
    "    with open(path, 'rb') as f:\n",
    "        img = pil_image.open(io.BytesIO(f.read()))\n",
    "        if color_mode == 'grayscale':\n",
    "            # if image is not already an 8-bit, 16-bit or 32-bit grayscale image\n",
    "            # convert it to an 8-bit grayscale image.\n",
    "            if img.mode not in ('L', 'I;16', 'I'):\n",
    "                img = img.convert('L')\n",
    "        elif color_mode == 'rgba':\n",
    "            if img.mode != 'RGBA':\n",
    "                img = img.convert('RGBA')\n",
    "        elif color_mode == 'rgb':\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "        else:\n",
    "            raise ValueError('color_mode must be \"grayscale\", \"rgb\", or \"rgba\"')\n",
    "        if target_size is not None:\n",
    "            width_height_tuple = (target_size[1], target_size[0])\n",
    "            if img.size != width_height_tuple:\n",
    "                if interpolation not in _PIL_INTERPOLATION_METHODS:\n",
    "                    raise ValueError(\n",
    "                        'Invalid interpolation method {} specified. Supported '\n",
    "                        'methods are {}'.format(\n",
    "                            interpolation,\n",
    "                            \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n",
    "                resample = _PIL_INTERPOLATION_METHODS[interpolation]\n",
    "                img = img.resize(width_height_tuple, resample)\n",
    "        return img\n",
    "\n",
    "\n",
    "def list_pictures(directory, ext=('jpg', 'jpeg', 'bmp', 'png', 'ppm', 'tif',\n",
    "                                  'tiff')):\n",
    "    \"\"\"Lists all pictures in a directory, including all subdirectories.\n",
    "    # Arguments\n",
    "        directory: string, absolute path to the directory\n",
    "        ext: tuple of strings or single string, extensions of the pictures\n",
    "    # Returns\n",
    "        a list of paths\n",
    "    \"\"\"\n",
    "    ext = tuple('.%s' % e for e in ((ext,) if isinstance(ext, str) else ext))\n",
    "    return [os.path.join(root, f)\n",
    "            for root, _, files in os.walk(directory) for f in files\n",
    "            if f.lower().endswith(ext)]\n",
    "\n",
    "\n",
    "def _iter_valid_files(directory, white_list_formats, follow_links):\n",
    "    \"\"\"Iterates on files with extension in `white_list_formats` contained in `directory`.\n",
    "    # Arguments\n",
    "        directory: Absolute path to the directory\n",
    "            containing files to be counted\n",
    "        white_list_formats: Set of strings containing allowed extensions for\n",
    "            the files to be counted.\n",
    "        follow_links: Boolean, follow symbolic links to subdirectories.\n",
    "    # Yields\n",
    "        Tuple of (root, filename) with extension in `white_list_formats`.\n",
    "    \"\"\"\n",
    "    def _recursive_list(subpath):\n",
    "        return sorted(os.walk(subpath, followlinks=follow_links),\n",
    "                      key=lambda x: x[0])\n",
    "\n",
    "    for root, _, files in _recursive_list(directory):\n",
    "        for fname in sorted(files):\n",
    "            if fname.lower().endswith('.tiff'):\n",
    "                warnings.warn('Using \".tiff\" files with multiple bands '\n",
    "                              'will cause distortion. Please verify your output.')\n",
    "            if fname.lower().endswith(white_list_formats):\n",
    "                yield root, fname\n",
    "\n",
    "\n",
    "def _list_valid_filenames_in_directory(directory, white_list_formats, split,\n",
    "                                       class_indices, follow_links):\n",
    "    \"\"\"Lists paths of files in `subdir` with extensions in `white_list_formats`.\n",
    "    # Arguments\n",
    "        directory: absolute path to a directory containing the files to list.\n",
    "            The directory name is used as class label\n",
    "            and must be a key of `class_indices`.\n",
    "        white_list_formats: set of strings containing allowed extensions for\n",
    "            the files to be counted.\n",
    "        split: tuple of floats (e.g. `(0.2, 0.6)`) to only take into\n",
    "            account a certain fraction of files in each directory.\n",
    "            E.g.: `segment=(0.6, 1.0)` would only account for last 40 percent\n",
    "            of images in each directory.\n",
    "        class_indices: dictionary mapping a class name to its index.\n",
    "        follow_links: boolean, follow symbolic links to subdirectories.\n",
    "    # Returns\n",
    "         classes: a list of class indices\n",
    "         filenames: the path of valid files in `directory`, relative from\n",
    "             `directory`'s parent (e.g., if `directory` is \"dataset/class1\",\n",
    "            the filenames will be\n",
    "            `[\"class1/file1.jpg\", \"class1/file2.jpg\", ...]`).\n",
    "    \"\"\"\n",
    "    dirname = os.path.basename(directory)\n",
    "    if split:\n",
    "        all_files = list(_iter_valid_files(directory, white_list_formats,\n",
    "                                           follow_links))\n",
    "        num_files = len(all_files)\n",
    "        start, stop = int(split[0] * num_files), int(split[1] * num_files)\n",
    "        valid_files = all_files[start: stop]\n",
    "    else:\n",
    "        valid_files = _iter_valid_files(\n",
    "            directory, white_list_formats, follow_links)\n",
    "    classes = []\n",
    "    filenames = []\n",
    "    for root, fname in valid_files:\n",
    "        classes.append(class_indices[dirname])\n",
    "        absolute_path = os.path.join(root, fname)\n",
    "        relative_path = os.path.join(\n",
    "            dirname, os.path.relpath(absolute_path, directory))\n",
    "        filenames.append(relative_path)\n",
    "\n",
    "    return classes, filenames\n",
    "\n",
    "\n",
    "def array_to_img(x, data_format='channels_last', scale=True, dtype='float32'):\n",
    "    \"\"\"Converts a 3D Numpy array to a PIL Image instance.\n",
    "    # Arguments\n",
    "        x: Input Numpy array.\n",
    "        data_format: Image data format, either \"channels_first\" or \"channels_last\".\n",
    "            Default: \"channels_last\".\n",
    "        scale: Whether to rescale the image such that minimum and maximum values\n",
    "            are 0 and 255 respectively.\n",
    "            Default: True.\n",
    "        dtype: Dtype to use.\n",
    "            Default: \"float32\".\n",
    "    # Returns\n",
    "        A PIL Image instance.\n",
    "    # Raises\n",
    "        ImportError: if PIL is not available.\n",
    "        ValueError: if invalid `x` or `data_format` is passed.\n",
    "    \"\"\"\n",
    "    if pil_image is None:\n",
    "        raise ImportError('Could not import PIL.Image. '\n",
    "                          'The use of `array_to_img` requires PIL.')\n",
    "    x = np.asarray(x, dtype=dtype)\n",
    "    if x.ndim != 3:\n",
    "        raise ValueError('Expected image array to have rank 3 (single image). '\n",
    "                         'Got array with shape: %s' % (x.shape,))\n",
    "\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Invalid data_format: %s' % data_format)\n",
    "\n",
    "    # Original Numpy array x has format (height, width, channel)\n",
    "    # or (channel, height, width)\n",
    "    # but target PIL image has format (width, height, channel)\n",
    "    if data_format == 'channels_first':\n",
    "        x = x.transpose(1, 2, 0)\n",
    "    if scale:\n",
    "        x = x - np.min(x)\n",
    "        x_max = np.max(x)\n",
    "        if x_max != 0:\n",
    "            x /= x_max\n",
    "        x *= 255\n",
    "    if x.shape[2] == 4:\n",
    "        # RGBA\n",
    "        return pil_image.fromarray(x.astype('uint8'), 'RGBA')\n",
    "    elif x.shape[2] == 3:\n",
    "        # RGB\n",
    "        return pil_image.fromarray(x.astype('uint8'), 'RGB')\n",
    "    elif x.shape[2] == 1:\n",
    "        # grayscale\n",
    "        if np.max(x) > 255:\n",
    "            # 32-bit signed integer grayscale image. PIL mode \"I\"\n",
    "            return pil_image.fromarray(x[:, :, 0].astype('int32'), 'I')\n",
    "        return pil_image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n",
    "    else:\n",
    "        raise ValueError('Unsupported channel number: %s' % (x.shape[2],))\n",
    "\n",
    "\n",
    "def img_to_array(img, data_format='channels_last', dtype='float32'):\n",
    "    \"\"\"Converts a PIL Image instance to a Numpy array.\n",
    "    # Arguments\n",
    "        img: PIL Image instance.\n",
    "        data_format: Image data format,\n",
    "            either \"channels_first\" or \"channels_last\".\n",
    "        dtype: Dtype to use for the returned array.\n",
    "    # Returns\n",
    "        A 3D Numpy array.\n",
    "    # Raises\n",
    "        ValueError: if invalid `img` or `data_format` is passed.\n",
    "    \"\"\"\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format: %s' % data_format)\n",
    "    # Numpy array x has format (height, width, channel)\n",
    "    # or (channel, height, width)\n",
    "    # but original PIL image has format (width, height, channel)\n",
    "    x = np.asarray(img, dtype=dtype)\n",
    "    if len(x.shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.transpose(2, 0, 1)\n",
    "    elif len(x.shape) == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "        else:\n",
    "            x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "    else:\n",
    "        raise ValueError('Unsupported image shape: %s' % (x.shape,))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for real-time data augmentation on image data.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import threading\n",
    "import numpy as np\n",
    "from keras_preprocessing import get_keras_submodule\n",
    "\n",
    "try:\n",
    "    IteratorType = get_keras_submodule('utils').Sequence\n",
    "except ImportError:\n",
    "    IteratorType = object\n",
    "\n",
    "\n",
    "class Iterator(IteratorType):\n",
    "    \"\"\"Base class for image data iterators.\n",
    "    Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n",
    "    method.\n",
    "    # Arguments\n",
    "        n: Integer, total number of samples in the dataset to loop over.\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seeding for data shuffling.\n",
    "    \"\"\"\n",
    "    white_list_formats = ('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')\n",
    "\n",
    "    def __init__(self, n, batch_size, shuffle, seed):\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_index = 0\n",
    "        self.total_batches_seen = 0\n",
    "        self.lock = threading.Lock()\n",
    "        self.index_array = None\n",
    "        self.index_generator = self._flow_index()\n",
    "\n",
    "    def _set_index_array(self):\n",
    "        self.index_array = np.arange(self.n)\n",
    "        if self.shuffle:\n",
    "            self.index_array = np.random.permutation(self.n)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise ValueError('Asked to retrieve element {idx}, '\n",
    "                             'but the Sequence '\n",
    "                             'has length {length}'.format(idx=idx,\n",
    "                                                          length=len(self)))\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed + self.total_batches_seen)\n",
    "        self.total_batches_seen += 1\n",
    "        if self.index_array is None:\n",
    "            self._set_index_array()\n",
    "        index_array = self.index_array[self.batch_size * idx:\n",
    "                                       self.batch_size * (idx + 1)]\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size  # round up\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self._set_index_array()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def _flow_index(self):\n",
    "        # Ensure self.batch_index is 0.\n",
    "        self.reset()\n",
    "        while 1:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed + self.total_batches_seen)\n",
    "            if self.batch_index == 0:\n",
    "                self._set_index_array()\n",
    "\n",
    "            if self.n == 0:\n",
    "                # Avoiding modulo by zero error\n",
    "                current_index = 0\n",
    "            else:\n",
    "                current_index = (self.batch_index * self.batch_size) % self.n\n",
    "            if self.n > current_index + self.batch_size:\n",
    "                self.batch_index += 1\n",
    "            else:\n",
    "                self.batch_index = 0\n",
    "            self.total_batches_seen += 1\n",
    "            yield self.index_array[current_index:\n",
    "                                   current_index + self.batch_size]\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Needed if we want to do something like:\n",
    "        # for x, y in data_gen.flow(...):\n",
    "        return self\n",
    "\n",
    "    def __next__(self, *args, **kwargs):\n",
    "        return self.next(*args, **kwargs)\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"Gets a batch of transformed samples.\n",
    "        # Arguments\n",
    "            index_array: Array of sample indices to include in batch.\n",
    "        # Returns\n",
    "            A batch of transformed samples.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class BatchFromFilesMixin():\n",
    "    \"\"\"Adds methods related to getting batches from filenames\n",
    "    It includes the logic to transform image files to batches.\n",
    "    \"\"\"\n",
    "\n",
    "    def set_processing_attrs(self,\n",
    "                             image_data_generator,\n",
    "                             target_size,\n",
    "                             color_mode,\n",
    "                             data_format,\n",
    "                             save_to_dir,\n",
    "                             save_prefix,\n",
    "                             save_format,\n",
    "                             subset,\n",
    "                             interpolation):\n",
    "        \"\"\"Sets attributes to use later for processing files into a batch.\n",
    "        # Arguments\n",
    "            image_data_generator: Instance of `ImageDataGenerator`\n",
    "                to use for random transformations and normalization.\n",
    "            target_size: tuple of integers, dimensions to resize input images to.\n",
    "            color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n",
    "                Color mode to read images.\n",
    "            data_format: String, one of `channels_first`, `channels_last`.\n",
    "            save_to_dir: Optional directory where to save the pictures\n",
    "                being yielded, in a viewable format. This is useful\n",
    "                for visualizing the random transformations being\n",
    "                applied, for debugging purposes.\n",
    "            save_prefix: String prefix to use for saving sample\n",
    "                images (if `save_to_dir` is set).\n",
    "            save_format: Format to use for saving sample images\n",
    "                (if `save_to_dir` is set).\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "                validation_split is set in ImageDataGenerator.\n",
    "            interpolation: Interpolation method used to resample the image if the\n",
    "                target size is different from that of the loaded image.\n",
    "                Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
    "                If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
    "                supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
    "                \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "        \"\"\"\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        if color_mode not in {'rgb', 'rgba', 'grayscale'}:\n",
    "            raise ValueError('Invalid color mode:', color_mode,\n",
    "                             '; expected \"rgb\", \"rgba\", or \"grayscale\".')\n",
    "        self.color_mode = color_mode\n",
    "        self.data_format = data_format\n",
    "        if self.color_mode == 'rgba':\n",
    "            if self.data_format == 'channels_last':\n",
    "                self.image_shape = self.target_size + (4,)\n",
    "            else:\n",
    "                self.image_shape = (4,) + self.target_size\n",
    "        elif self.color_mode == 'rgb':\n",
    "            if self.data_format == 'channels_last':\n",
    "                self.image_shape = self.target_size + (3,)\n",
    "            else:\n",
    "                self.image_shape = (3,) + self.target_size\n",
    "        else:\n",
    "            if self.data_format == 'channels_last':\n",
    "                self.image_shape = self.target_size + (1,)\n",
    "            else:\n",
    "                self.image_shape = (1,) + self.target_size\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        self.interpolation = interpolation\n",
    "        if subset is not None:\n",
    "            validation_split = self.image_data_generator._validation_split\n",
    "            if subset == 'validation':\n",
    "                split = (0, validation_split)\n",
    "            elif subset == 'training':\n",
    "                split = (validation_split, 1)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'Invalid subset name: %s;'\n",
    "                    'expected \"training\" or \"validation\"' % (subset,))\n",
    "        else:\n",
    "            split = None\n",
    "        self.split = split\n",
    "        self.subset = subset\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"Gets a batch of transformed samples.\n",
    "        # Arguments\n",
    "            index_array: Array of sample indices to include in batch.\n",
    "        # Returns\n",
    "            A batch of transformed samples.\n",
    "        \"\"\"\n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n",
    "        # build batch of image data\n",
    "        # self.filepaths is dynamic, is better to call it once outside the loop\n",
    "        filepaths = self.filepaths\n",
    "        for i, j in enumerate(index_array):\n",
    "            img = load_img(filepaths[j],\n",
    "                           color_mode=self.color_mode,\n",
    "                           target_size=self.target_size,\n",
    "                           interpolation=self.interpolation)\n",
    "            x = img_to_array(img, data_format=self.data_format)\n",
    "            # Pillow images should be closed after `load_img`,\n",
    "            # but not PIL images.\n",
    "            if hasattr(img, 'close'):\n",
    "                img.close()\n",
    "            if self.image_data_generator:\n",
    "                params = self.image_data_generator.get_random_transform(x.shape)\n",
    "                x = self.image_data_generator.apply_transform(x, params)\n",
    "                x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        # optionally save augmented images to disk for debugging purposes\n",
    "        if self.save_to_dir:\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(\n",
    "                    prefix=self.save_prefix,\n",
    "                    index=j,\n",
    "                    hash=np.random.randint(1e7),\n",
    "                    format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        # build batch of labels\n",
    "        if self.class_mode == 'input':\n",
    "            batch_y = batch_x.copy()\n",
    "        elif self.class_mode in {'binary', 'sparse'}:\n",
    "            batch_y = np.empty(len(batch_x), dtype=self.dtype)\n",
    "            for i, n_observation in enumerate(index_array):\n",
    "                batch_y[i] = self.classes[n_observation]\n",
    "        elif self.class_mode == 'categorical':\n",
    "            batch_y = np.zeros((len(batch_x), len(self.class_indices)),\n",
    "                               dtype=self.dtype)\n",
    "            for i, n_observation in enumerate(index_array):\n",
    "                batch_y[i, self.classes[n_observation]] = 1.\n",
    "        elif self.class_mode == 'multi_output':\n",
    "            batch_y = [output[index_array] for output in self.labels]\n",
    "        elif self.class_mode == 'raw':\n",
    "            batch_y = self.labels[index_array]\n",
    "        else:\n",
    "            return batch_x\n",
    "        if self.sample_weight is None:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x, batch_y, self.sample_weight[index_array]\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        \"\"\"List of absolute paths to image files\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            '`filepaths` property method has not been implemented in {}.'\n",
    "            .format(type(self).__name__)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"Class labels of every observation\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            '`labels` property method has not been implemented in {}.'\n",
    "            .format(type(self).__name__)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def sample_weight(self):\n",
    "        raise NotImplementedError(\n",
    "            '`sample_weight` property method has not been implemented in {}.'\n",
    "            .format(type(self).__name__)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import multiprocessing.pool\n",
    "from six.moves import range\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from .iterator import BatchFromFilesMixin, Iterator\n",
    "\n",
    "\n",
    "class DirectoryIterator(BatchFromFilesMixin, Iterator):\n",
    "    \"\"\"Iterator capable of reading images from a directory on disk.\n",
    "    # Arguments\n",
    "        directory: string, path to the directory to read images from.\n",
    "            Each subdirectory in this directory will be\n",
    "            considered to contain images from one class,\n",
    "            or alternatively you could specify class subdirectories\n",
    "            via the `classes` argument.\n",
    "        image_data_generator: Instance of `ImageDataGenerator`\n",
    "            to use for random transformations and normalization.\n",
    "        target_size: tuple of integers, dimensions to resize input images to.\n",
    "        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n",
    "            Color mode to read images.\n",
    "        classes: Optional list of strings, names of subdirectories\n",
    "            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n",
    "            It will be computed automatically if not set.\n",
    "        class_mode: Mode for yielding the targets:\n",
    "            `\"binary\"`: binary targets (if there are only two classes),\n",
    "            `\"categorical\"`: categorical targets,\n",
    "            `\"sparse\"`: integer targets,\n",
    "            `\"input\"`: targets are images identical to input images (mainly\n",
    "                used to work with autoencoders),\n",
    "            `None`: no targets get yielded (only input images are yielded).\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "            If set to False, sorts the data in alphanumeric order.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures\n",
    "            being yielded, in a viewable format. This is useful\n",
    "            for visualizing the random transformations being\n",
    "            applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample\n",
    "            images (if `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images\n",
    "            (if `save_to_dir` is set).\n",
    "        follow_links: boolean,follow symbolic links to subdirectories\n",
    "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "            validation_split is set in ImageDataGenerator.\n",
    "        interpolation: Interpolation method used to resample the image if the\n",
    "            target size is different from that of the loaded image.\n",
    "            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
    "            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
    "            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
    "            \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "        dtype: Dtype to use for generated arrays.\n",
    "    \"\"\"\n",
    "    allowed_class_modes = {'categorical', 'binary', 'sparse', 'input', None}\n",
    "\n",
    "    def __init__(self,\n",
    "                 directory,\n",
    "                 image_data_generator,\n",
    "                 target_size=(256, 256),\n",
    "                 color_mode='rgb',\n",
    "                 classes=None,\n",
    "                 class_mode='categorical',\n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 seed=None,\n",
    "                 data_format='channels_last',\n",
    "                 save_to_dir=None,\n",
    "                 save_prefix='',\n",
    "                 save_format='png',\n",
    "                 follow_links=False,\n",
    "                 subset=None,\n",
    "                 interpolation='nearest',\n",
    "                 dtype='float32'):\n",
    "        super(DirectoryIterator, self).set_processing_attrs(image_data_generator,\n",
    "                                                            target_size,\n",
    "                                                            color_mode,\n",
    "                                                            data_format,\n",
    "                                                            save_to_dir,\n",
    "                                                            save_prefix,\n",
    "                                                            save_format,\n",
    "                                                            subset,\n",
    "                                                            interpolation)\n",
    "        self.directory = directory\n",
    "        self.classes = classes\n",
    "        if class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError('Invalid class_mode: {}; expected one of: {}'\n",
    "                             .format(class_mode, self.allowed_class_modes))\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        # First, count the number of samples and classes.\n",
    "        self.samples = 0\n",
    "\n",
    "        if not classes:\n",
    "            classes = []\n",
    "            for subdir in sorted(os.listdir(directory)):\n",
    "                if os.path.isdir(os.path.join(directory, subdir)):\n",
    "                    classes.append(subdir)\n",
    "        self.num_classes = len(classes)\n",
    "        self.class_indices = dict(zip(classes, range(len(classes))))\n",
    "\n",
    "        pool = multiprocessing.pool.ThreadPool()\n",
    "\n",
    "        # Second, build an index of the images\n",
    "        # in the different class subfolders.\n",
    "        results = []\n",
    "        self.filenames = []\n",
    "        i = 0\n",
    "        for dirpath in (os.path.join(directory, subdir) for subdir in classes):\n",
    "            results.append(\n",
    "                pool.apply_async(_list_valid_filenames_in_directory,\n",
    "                                 (dirpath, self.white_list_formats, self.split,\n",
    "                                  self.class_indices, follow_links)))\n",
    "        classes_list = []\n",
    "        for res in results:\n",
    "            classes, filenames = res.get()\n",
    "            classes_list.append(classes)\n",
    "            self.filenames += filenames\n",
    "        self.samples = len(self.filenames)\n",
    "        self.classes = np.zeros((self.samples,), dtype='int32')\n",
    "        for classes in classes_list:\n",
    "            self.classes[i:i + len(classes)] = classes\n",
    "            i += len(classes)\n",
    "\n",
    "        print('Found %d images belonging to %d classes.' %\n",
    "              (self.samples, self.num_classes))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        self._filepaths = [\n",
    "            os.path.join(self.directory, fname) for fname in self.filenames\n",
    "        ]\n",
    "        super(DirectoryIterator, self).__init__(self.samples,\n",
    "                                                batch_size,\n",
    "                                                shuffle,\n",
    "                                                seed)\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        return self._filepaths\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self.classes\n",
    "\n",
    "    @property  # mixin needs this property to work\n",
    "    def sample_weight(self):\n",
    "        # no sample weights will be returned\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for performing affine transformations on image data.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    # scipy.ndimage cannot be accessed until explicitly imported\n",
    "    from scipy import ndimage\n",
    "except ImportError:\n",
    "    scipy = None\n",
    "\n",
    "try:\n",
    "    from PIL import ImageEnhance\n",
    "    from PIL import Image as pil_image\n",
    "except ImportError:\n",
    "    pil_image = None\n",
    "    ImageEnhance = None\n",
    "\n",
    "\n",
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                    fill_mode='nearest', cval=0., interpolation_order=1):\n",
    "    \"\"\"Performs a random rotation of a Numpy image tensor.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        rg: Rotation range, in degrees.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "    # Returns\n",
    "        Rotated Numpy image tensor.\n",
    "    \"\"\"\n",
    "    theta = np.random.uniform(-rg, rg)\n",
    "    x = apply_affine_transform(x, theta=theta, channel_axis=channel_axis,\n",
    "                               fill_mode=fill_mode, cval=cval,\n",
    "                               order=interpolation_order)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                 fill_mode='nearest', cval=0., interpolation_order=1):\n",
    "    \"\"\"Performs a random spatial shift of a Numpy image tensor.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        wrg: Width shift range, as a float fraction of the width.\n",
    "        hrg: Height shift range, as a float fraction of the height.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "    # Returns\n",
    "        Shifted Numpy image tensor.\n",
    "    \"\"\"\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    tx = np.random.uniform(-hrg, hrg) * h\n",
    "    ty = np.random.uniform(-wrg, wrg) * w\n",
    "    x = apply_affine_transform(x, tx=tx, ty=ty, channel_axis=channel_axis,\n",
    "                               fill_mode=fill_mode, cval=cval,\n",
    "                               order=interpolation_order)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                 fill_mode='nearest', cval=0., interpolation_order=1):\n",
    "    \"\"\"Performs a random spatial shear of a Numpy image tensor.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity: Transformation intensity in degrees.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "    # Returns\n",
    "        Sheared Numpy image tensor.\n",
    "    \"\"\"\n",
    "    shear = np.random.uniform(-intensity, intensity)\n",
    "    x = apply_affine_transform(x, shear=shear, channel_axis=channel_axis,\n",
    "                               fill_mode=fill_mode, cval=cval,\n",
    "                               order=interpolation_order)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                fill_mode='nearest', cval=0., interpolation_order=1):\n",
    "    \"\"\"Performs a random spatial zoom of a Numpy image tensor.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        zoom_range: Tuple of floats; zoom range for width and height.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "    # Returns\n",
    "        Zoomed Numpy image tensor.\n",
    "    # Raises\n",
    "        ValueError: if `zoom_range` isn't a tuple.\n",
    "    \"\"\"\n",
    "    if len(zoom_range) != 2:\n",
    "        raise ValueError('`zoom_range` should be a tuple or list of two'\n",
    "                         ' floats. Received: %s' % (zoom_range,))\n",
    "\n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "    x = apply_affine_transform(x, zx=zx, zy=zy, channel_axis=channel_axis,\n",
    "                               fill_mode=fill_mode, cval=cval,\n",
    "                               order=interpolation_order)\n",
    "    return x\n",
    "\n",
    "\n",
    "def apply_channel_shift(x, intensity, channel_axis=0):\n",
    "    \"\"\"Performs a channel shift.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity: Transformation intensity.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "    # Returns\n",
    "        Numpy image tensor.\n",
    "    \"\"\"\n",
    "    x = np.rollaxis(x, channel_axis, 0)\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    channel_images = [\n",
    "        np.clip(x_channel + intensity,\n",
    "                min_x,\n",
    "                max_x)\n",
    "        for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_channel_shift(x, intensity_range, channel_axis=0):\n",
    "    \"\"\"Performs a random channel shift.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity_range: Transformation intensity.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "    # Returns\n",
    "        Numpy image tensor.\n",
    "    \"\"\"\n",
    "    intensity = np.random.uniform(-intensity_range, intensity_range)\n",
    "    return apply_channel_shift(x, intensity, channel_axis=channel_axis)\n",
    "\n",
    "\n",
    "def apply_brightness_shift(x, brightness):\n",
    "    \"\"\"Performs a brightness shift.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        brightness: Float. The new brightness value.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "    # Returns\n",
    "        Numpy image tensor.\n",
    "    # Raises\n",
    "        ValueError if `brightness_range` isn't a tuple.\n",
    "    \"\"\"\n",
    "    if ImageEnhance is None:\n",
    "        raise ImportError('Using brightness shifts requires PIL. '\n",
    "                          'Install PIL or Pillow.')\n",
    "    x = array_to_img(x)\n",
    "    x = imgenhancer_Brightness = ImageEnhance.Brightness(x)\n",
    "    x = imgenhancer_Brightness.enhance(brightness)\n",
    "    x = img_to_array(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_brightness(x, brightness_range):\n",
    "    \"\"\"Performs a random brightness shift.\n",
    "    # Arguments\n",
    "        x: Input tensor. Must be 3D.\n",
    "        brightness_range: Tuple of floats; brightness range.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "    # Returns\n",
    "        Numpy image tensor.\n",
    "    # Raises\n",
    "        ValueError if `brightness_range` isn't a tuple.\n",
    "    \"\"\"\n",
    "    if len(brightness_range) != 2:\n",
    "        raise ValueError(\n",
    "            '`brightness_range should be tuple or list of two floats. '\n",
    "            'Received: %s' % (brightness_range,))\n",
    "\n",
    "    u = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "    return apply_brightness_shift(x, u)\n",
    "\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "\n",
    "def apply_affine_transform(x, theta=0, tx=0, ty=0, shear=0, zx=1, zy=1,\n",
    "                           row_axis=0, col_axis=1, channel_axis=2,\n",
    "                           fill_mode='nearest', cval=0., order=1):\n",
    "    \"\"\"Applies an affine transformation specified by the parameters given.\n",
    "    # Arguments\n",
    "        x: 2D numpy array, single image.\n",
    "        theta: Rotation angle in degrees.\n",
    "        tx: Width shift.\n",
    "        ty: Heigh shift.\n",
    "        shear: Shear angle in degrees.\n",
    "        zx: Zoom in x direction.\n",
    "        zy: Zoom in y direction\n",
    "        row_axis: Index of axis for rows in the input image.\n",
    "        col_axis: Index of axis for columns in the input image.\n",
    "        channel_axis: Index of axis for channels in the input image.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        order: int, order of interpolation\n",
    "    # Returns\n",
    "        The transformed version of the input.\n",
    "    \"\"\"\n",
    "    if scipy is None:\n",
    "        raise ImportError('Image transformations require SciPy. '\n",
    "                          'Install SciPy.')\n",
    "    transform_matrix = None\n",
    "    if theta != 0:\n",
    "        theta = np.deg2rad(theta)\n",
    "        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                    [np.sin(theta), np.cos(theta), 0],\n",
    "                                    [0, 0, 1]])\n",
    "        transform_matrix = rotation_matrix\n",
    "\n",
    "    if tx != 0 or ty != 0:\n",
    "        shift_matrix = np.array([[1, 0, tx],\n",
    "                                 [0, 1, ty],\n",
    "                                 [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shift_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
    "\n",
    "    if shear != 0:\n",
    "        shear = np.deg2rad(shear)\n",
    "        shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
    "                                 [0, np.cos(shear), 0],\n",
    "                                 [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shear_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shear_matrix)\n",
    "\n",
    "    if zx != 1 or zy != 1:\n",
    "        zoom_matrix = np.array([[zx, 0, 0],\n",
    "                                [0, zy, 0],\n",
    "                                [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = zoom_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
    "\n",
    "    if transform_matrix is not None:\n",
    "        h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "        transform_matrix = transform_matrix_offset_center(\n",
    "            transform_matrix, h, w)\n",
    "        x = np.rollaxis(x, channel_axis, 0)\n",
    "        final_affine_matrix = transform_matrix[:2, :2]\n",
    "        final_offset = transform_matrix[:2, 2]\n",
    "\n",
    "        channel_images = [ndimage.interpolation.affine_transform(\n",
    "            x_channel,\n",
    "            final_affine_matrix,\n",
    "            final_offset,\n",
    "            order=order,\n",
    "            mode=fill_mode,\n",
    "            cval=cval) for x_channel in x]\n",
    "        x = np.stack(channel_images, axis=0)\n",
    "        x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for real-time data augmentation on image data.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "from six.moves import range\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    # scipy.linalg cannot be accessed until explicitly imported\n",
    "    from scipy import linalg\n",
    "    # scipy.ndimage cannot be accessed until explicitly imported\n",
    "except ImportError:\n",
    "    scipy = None\n",
    "\n",
    "# from .directory_iterator import DirectoryIterator\n",
    "# from .affine_transformations import (apply_affine_transform,\n",
    "#                                      apply_brightness_shift,\n",
    "#                                      apply_channel_shift,\n",
    "#                                      flip_axis)\n",
    "\n",
    "\n",
    "class ImageDataGenerator(object):\n",
    "    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n",
    "     The data will be looped over (in batches).\n",
    "    # Arguments\n",
    "        featurewise_center: Boolean.\n",
    "            Set input mean to 0 over the dataset, feature-wise.\n",
    "        samplewise_center: Boolean. Set each sample mean to 0.\n",
    "        featurewise_std_normalization: Boolean.\n",
    "            Divide inputs by std of the dataset, feature-wise.\n",
    "        samplewise_std_normalization: Boolean. Divide each input by its std.\n",
    "        zca_whitening: Boolean. Apply ZCA whitening.\n",
    "        zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n",
    "        rotation_range: Int. Degree range for random rotations.\n",
    "        width_shift_range: Float, 1-D array-like or int\n",
    "            - float: fraction of total width, if < 1, or pixels if >= 1.\n",
    "            - 1-D array-like: random elements from the array.\n",
    "            - int: integer number of pixels from interval\n",
    "                `(-width_shift_range, +width_shift_range)`\n",
    "            - With `width_shift_range=2` possible values\n",
    "                are integers `[-1, 0, +1]`,\n",
    "                same as with `width_shift_range=[-1, 0, +1]`,\n",
    "                while with `width_shift_range=1.0` possible values are floats\n",
    "                in the interval `[-1.0, +1.0)`.\n",
    "        height_shift_range: Float, 1-D array-like or int\n",
    "            - float: fraction of total height, if < 1, or pixels if >= 1.\n",
    "            - 1-D array-like: random elements from the array.\n",
    "            - int: integer number of pixels from interval\n",
    "                `(-height_shift_range, +height_shift_range)`\n",
    "            - With `height_shift_range=2` possible values\n",
    "                are integers `[-1, 0, +1]`,\n",
    "                same as with `height_shift_range=[-1, 0, +1]`,\n",
    "                while with `height_shift_range=1.0` possible values are floats\n",
    "                in the interval `[-1.0, +1.0)`.\n",
    "        brightness_range: Tuple or list of two floats. Range for picking\n",
    "            a brightness shift value from.\n",
    "        shear_range: Float. Shear Intensity\n",
    "            (Shear angle in counter-clockwise direction in degrees)\n",
    "        zoom_range: Float or [lower, upper]. Range for random zoom.\n",
    "            If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n",
    "        channel_shift_range: Float. Range for random channel shifts.\n",
    "        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.\n",
    "            Default is 'nearest'.\n",
    "            Points outside the boundaries of the input are filled\n",
    "            according to the given mode:\n",
    "            - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n",
    "            - 'nearest':  aaaaaaaa|abcd|dddddddd\n",
    "            - 'reflect':  abcddcba|abcd|dcbaabcd\n",
    "            - 'wrap':  abcdabcd|abcd|abcdabcd\n",
    "        cval: Float or Int.\n",
    "            Value used for points outside the boundaries\n",
    "            when `fill_mode = \"constant\"`.\n",
    "        horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
    "        vertical_flip: Boolean. Randomly flip inputs vertically.\n",
    "        rescale: rescaling factor. Defaults to None.\n",
    "            If None or 0, no rescaling is applied,\n",
    "            otherwise we multiply the data by the value provided\n",
    "            (after applying all other transformations).\n",
    "        preprocessing_function: function that will be applied on each input.\n",
    "            The function will run after the image is resized and augmented.\n",
    "            The function should take one argument:\n",
    "            one image (NumPy tensor with rank 3),\n",
    "            and should output a NumPy tensor with the same shape.\n",
    "        data_format: Image data format,\n",
    "            either \"channels_first\" or \"channels_last\".\n",
    "            \"channels_last\" mode means that the images should have shape\n",
    "            `(samples, height, width, channels)`,\n",
    "            \"channels_first\" mode means that the images should have shape\n",
    "            `(samples, channels, height, width)`.\n",
    "            It defaults to the `image_data_format` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be \"channels_last\".\n",
    "        validation_split: Float. Fraction of images reserved for validation\n",
    "            (strictly between 0 and 1).\n",
    "        interpolation_order: int, order to use for\n",
    "            the spline interpolation. Higher is slower.\n",
    "        dtype: Dtype to use for the generated arrays.\n",
    "    # Examples\n",
    "    Example of using `.flow(x, y)`:\n",
    "    ```python\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                        steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "    # here's a more \"manual\" example\n",
    "    for e in range(epochs):\n",
    "        print('Epoch', e)\n",
    "        batches = 0\n",
    "        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "            model.fit(x_batch, y_batch)\n",
    "            batches += 1\n",
    "            if batches >= len(x_train) / 32:\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "    ```\n",
    "    Example of using `.flow_from_directory(directory)`:\n",
    "    ```python\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            'data/train',\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            'data/validation',\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "    model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2000,\n",
    "            epochs=50,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=800)\n",
    "    ```\n",
    "    Example of transforming images and masks together.\n",
    "    ```python\n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(featurewise_center=True,\n",
    "                         featurewise_std_normalization=True,\n",
    "                         rotation_range=90,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(images, augment=True, seed=seed)\n",
    "    mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        'data/images',\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        'data/masks',\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50)\n",
    "    ```\n",
    "    Example of using ```.flow_from_dataframe(dataframe, directory,\n",
    "                                            x_col, y_col)```:\n",
    "    ```python\n",
    "    train_df = pandas.read_csv(\"./train.csv\")\n",
    "    valid_df = pandas.read_csv(\"./valid.csv\")\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=train_df,\n",
    "            directory='data/train',\n",
    "            x_col=\"filename\",\n",
    "            y_col=\"class\",\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "    validation_generator = test_datagen.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory='data/validation',\n",
    "            x_col=\"filename\",\n",
    "            y_col=\"class\",\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "    model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2000,\n",
    "            epochs=50,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=800)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 featurewise_center=False,\n",
    "                 samplewise_center=False,\n",
    "                 featurewise_std_normalization=False,\n",
    "                 samplewise_std_normalization=False,\n",
    "                 zca_whitening=False,\n",
    "                 zca_epsilon=1e-6,\n",
    "                 rotation_range=0,\n",
    "                 width_shift_range=0.,\n",
    "                 height_shift_range=0.,\n",
    "                 brightness_range=None,\n",
    "                 shear_range=0.,\n",
    "                 zoom_range=0.,\n",
    "                 channel_shift_range=0.,\n",
    "                 fill_mode='nearest',\n",
    "                 cval=0.,\n",
    "                 horizontal_flip=False,\n",
    "                 vertical_flip=False,\n",
    "                 rescale=None,\n",
    "                 preprocessing_function=None,\n",
    "                 data_format='channels_last',\n",
    "                 validation_split=0.0,\n",
    "                 interpolation_order=1,\n",
    "                 dtype='float32'):\n",
    "\n",
    "        self.featurewise_center = featurewise_center\n",
    "        self.samplewise_center = samplewise_center\n",
    "        self.featurewise_std_normalization = featurewise_std_normalization\n",
    "        self.samplewise_std_normalization = samplewise_std_normalization\n",
    "        self.zca_whitening = zca_whitening\n",
    "        self.zca_epsilon = zca_epsilon\n",
    "        self.rotation_range = rotation_range\n",
    "        self.width_shift_range = width_shift_range\n",
    "        self.height_shift_range = height_shift_range\n",
    "        self.shear_range = shear_range\n",
    "        self.zoom_range = zoom_range\n",
    "        self.channel_shift_range = channel_shift_range\n",
    "        self.fill_mode = fill_mode\n",
    "        self.cval = cval\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.vertical_flip = vertical_flip\n",
    "        self.rescale = rescale\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.dtype = dtype\n",
    "        self.interpolation_order = interpolation_order\n",
    "\n",
    "        if data_format not in {'channels_last', 'channels_first'}:\n",
    "            raise ValueError(\n",
    "                '`data_format` should be `\"channels_last\"` '\n",
    "                '(channel after row and column) or '\n",
    "                '`\"channels_first\"` (channel before row and column). '\n",
    "                'Received: %s' % data_format)\n",
    "        self.data_format = data_format\n",
    "        if data_format == 'channels_first':\n",
    "            self.channel_axis = 1\n",
    "            self.row_axis = 2\n",
    "            self.col_axis = 3\n",
    "        if data_format == 'channels_last':\n",
    "            self.channel_axis = 3\n",
    "            self.row_axis = 1\n",
    "            self.col_axis = 2\n",
    "        if validation_split and not 0 < validation_split < 1:\n",
    "            raise ValueError(\n",
    "                '`validation_split` must be strictly between 0 and 1. '\n",
    "                ' Received: %s' % validation_split)\n",
    "        self._validation_split = validation_split\n",
    "\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.principal_components = None\n",
    "\n",
    "        if isinstance(zoom_range, float):\n",
    "            self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n",
    "        elif (len(zoom_range) == 2 and\n",
    "              all(isinstance(val, float) for val in zoom_range)):\n",
    "            self.zoom_range = [zoom_range[0], zoom_range[1]]\n",
    "        else:\n",
    "            raise ValueError('`zoom_range` should be a float or '\n",
    "                             'a tuple or list of two floats. '\n",
    "                             'Received: %s' % (zoom_range,))\n",
    "        if zca_whitening:\n",
    "            if not featurewise_center:\n",
    "                self.featurewise_center = True\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`zca_whitening`, which overrides '\n",
    "                              'setting of `featurewise_center`.')\n",
    "            if featurewise_std_normalization:\n",
    "                self.featurewise_std_normalization = False\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`zca_whitening` '\n",
    "                              'which overrides setting of'\n",
    "                              '`featurewise_std_normalization`.')\n",
    "        if featurewise_std_normalization:\n",
    "            if not featurewise_center:\n",
    "                self.featurewise_center = True\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`featurewise_std_normalization`, '\n",
    "                              'which overrides setting of '\n",
    "                              '`featurewise_center`.')\n",
    "        if samplewise_std_normalization:\n",
    "            if not samplewise_center:\n",
    "                self.samplewise_center = True\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`samplewise_std_normalization`, '\n",
    "                              'which overrides setting of '\n",
    "                              '`samplewise_center`.')\n",
    "        if brightness_range is not None:\n",
    "            if (not isinstance(brightness_range, (tuple, list)) or\n",
    "                    len(brightness_range) != 2):\n",
    "                raise ValueError(\n",
    "                    '`brightness_range should be tuple or list of two floats. '\n",
    "                    'Received: %s' % (brightness_range,))\n",
    "        self.brightness_range = brightness_range\n",
    "\n",
    "    def flow_from_directory(self,\n",
    "                            directory,\n",
    "                            target_size=(256, 256),\n",
    "                            color_mode='rgb',\n",
    "                            classes=None,\n",
    "                            class_mode='categorical',\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            seed=None,\n",
    "                            save_to_dir=None,\n",
    "                            save_prefix='',\n",
    "                            save_format='png',\n",
    "                            follow_links=False,\n",
    "                            subset=None,\n",
    "                            interpolation='nearest'):\n",
    "        \"\"\"Takes the path to a directory & generates batches of augmented data.\n",
    "        # Arguments\n",
    "            directory: string, path to the target directory.\n",
    "                It should contain one subdirectory per class.\n",
    "                Any PNG, JPG, BMP, PPM or TIF images\n",
    "                inside each of the subdirectories directory tree\n",
    "                will be included in the generator.\n",
    "                See [this script](\n",
    "                https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
    "                for more details.\n",
    "            target_size: Tuple of integers `(height, width)`,\n",
    "                default: `(256, 256)`.\n",
    "                The dimensions to which all images found will be resized.\n",
    "            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "                Whether the images will be converted to\n",
    "                have 1, 3, or 4 channels.\n",
    "            classes: Optional list of class subdirectories\n",
    "                (e.g. `['dogs', 'cats']`). Default: None.\n",
    "                If not provided, the list of classes will be automatically\n",
    "                inferred from the subdirectory names/structure\n",
    "                under `directory`, where each subdirectory will\n",
    "                be treated as a different class\n",
    "                (and the order of the classes, which will map to the label\n",
    "                indices, will be alphanumeric).\n",
    "                The dictionary containing the mapping from class names to class\n",
    "                indices can be obtained via the attribute `class_indices`.\n",
    "            class_mode: One of \"categorical\", \"binary\", \"sparse\",\n",
    "                \"input\", or None. Default: \"categorical\".\n",
    "                Determines the type of label arrays that are returned:\n",
    "                - \"categorical\" will be 2D one-hot encoded labels,\n",
    "                - \"binary\" will be 1D binary labels,\n",
    "                    \"sparse\" will be 1D integer labels,\n",
    "                - \"input\" will be images identical\n",
    "                    to input images (mainly used to work with autoencoders).\n",
    "                - If None, no labels are returned\n",
    "                  (the generator will only yield batches of image data,\n",
    "                  which is useful to use with `model.predict_generator()`).\n",
    "                  Please note that in case of class_mode None,\n",
    "                  the data still needs to reside in a subdirectory\n",
    "                  of `directory` for it to work correctly.\n",
    "            batch_size: Size of the batches of data (default: 32).\n",
    "            shuffle: Whether to shuffle the data (default: True)\n",
    "                If set to False, sorts the data in alphanumeric order.\n",
    "            seed: Optional random seed for shuffling and transformations.\n",
    "            save_to_dir: None or str (default: None).\n",
    "                This allows you to optionally specify\n",
    "                a directory to which to save\n",
    "                the augmented pictures being generated\n",
    "                (useful for visualizing what you are doing).\n",
    "            save_prefix: Str. Prefix to use for filenames of saved pictures\n",
    "                (only relevant if `save_to_dir` is set).\n",
    "            save_format: One of \"png\", \"jpeg\"\n",
    "                (only relevant if `save_to_dir` is set). Default: \"png\".\n",
    "            follow_links: Whether to follow symlinks inside\n",
    "                class subdirectories (default: False).\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "                `validation_split` is set in `ImageDataGenerator`.\n",
    "            interpolation: Interpolation method used to\n",
    "                resample the image if the\n",
    "                target size is different from that of the loaded image.\n",
    "                Supported methods are `\"nearest\"`, `\"bilinear\"`,\n",
    "                and `\"bicubic\"`.\n",
    "                If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
    "                supported. If PIL version 3.4.0 or newer is installed,\n",
    "                `\"box\"` and `\"hamming\"` are also supported.\n",
    "                By default, `\"nearest\"` is used.\n",
    "        # Returns\n",
    "            A `DirectoryIterator` yielding tuples of `(x, y)`\n",
    "                where `x` is a NumPy array containing a batch\n",
    "                of images with shape `(batch_size, *target_size, channels)`\n",
    "                and `y` is a NumPy array of corresponding labels.\n",
    "        \"\"\"\n",
    "        return DirectoryIterator(\n",
    "            directory,\n",
    "            self,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            classes=classes,\n",
    "            class_mode=class_mode,\n",
    "            data_format=self.data_format,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            follow_links=follow_links,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "            dtype=self.dtype\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    def standardize(self, x):\n",
    "        \"\"\"Applies the normalization configuration in-place to a batch of inputs.\n",
    "        `x` is changed in-place since the function is mainly used internally\n",
    "        to standardize images and feed them to your network. If a copy of `x`\n",
    "        would be created instead it would have a significant performance cost.\n",
    "        If you want to apply this method without changing the input in-place\n",
    "        you can call the method creating a copy before:\n",
    "        standardize(np.copy(x))\n",
    "        # Arguments\n",
    "            x: Batch of inputs to be normalized.\n",
    "        # Returns\n",
    "            The inputs, normalized.\n",
    "        \"\"\"\n",
    "        if self.preprocessing_function:\n",
    "            x = self.preprocessing_function(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "        if self.samplewise_center:\n",
    "            x -= np.mean(x, keepdims=True)\n",
    "        if self.samplewise_std_normalization:\n",
    "            x /= (np.std(x, keepdims=True) + 1e-6)\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            if self.mean is not None:\n",
    "                x -= self.mean\n",
    "            else:\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`featurewise_center`, but it hasn\\'t '\n",
    "                              'been fit on any training data. Fit it '\n",
    "                              'first by calling `.fit(numpy_data)`.')\n",
    "        if self.featurewise_std_normalization:\n",
    "            if self.std is not None:\n",
    "                x /= (self.std + 1e-6)\n",
    "            else:\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`featurewise_std_normalization`, '\n",
    "                              'but it hasn\\'t '\n",
    "                              'been fit on any training data. Fit it '\n",
    "                              'first by calling `.fit(numpy_data)`.')\n",
    "        if self.zca_whitening:\n",
    "            if self.principal_components is not None:\n",
    "                flatx = np.reshape(x, (-1, np.prod(x.shape[-3:])))\n",
    "                whitex = np.dot(flatx, self.principal_components)\n",
    "                x = np.reshape(whitex, x.shape)\n",
    "            else:\n",
    "                warnings.warn('This ImageDataGenerator specifies '\n",
    "                              '`zca_whitening`, but it hasn\\'t '\n",
    "                              'been fit on any training data. Fit it '\n",
    "                              'first by calling `.fit(numpy_data)`.')\n",
    "        return x\n",
    "\n",
    "    def get_random_transform(self, img_shape, seed=None):\n",
    "        \"\"\"Generates random parameters for a transformation.\n",
    "        # Arguments\n",
    "            seed: Random seed.\n",
    "            img_shape: Tuple of integers.\n",
    "                Shape of the image that is transformed.\n",
    "        # Returns\n",
    "            A dictionary containing randomly chosen parameters describing the\n",
    "            transformation.\n",
    "        \"\"\"\n",
    "        img_row_axis = self.row_axis - 1\n",
    "        img_col_axis = self.col_axis - 1\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        if self.rotation_range:\n",
    "            theta = np.random.uniform(\n",
    "                -self.rotation_range,\n",
    "                self.rotation_range)\n",
    "        else:\n",
    "            theta = 0\n",
    "\n",
    "        if self.height_shift_range:\n",
    "            try:  # 1-D array-like or int\n",
    "                tx = np.random.choice(self.height_shift_range)\n",
    "                tx *= np.random.choice([-1, 1])\n",
    "            except ValueError:  # floating point\n",
    "                tx = np.random.uniform(-self.height_shift_range,\n",
    "                                       self.height_shift_range)\n",
    "            if np.max(self.height_shift_range) < 1:\n",
    "                tx *= img_shape[img_row_axis]\n",
    "        else:\n",
    "            tx = 0\n",
    "\n",
    "        if self.width_shift_range:\n",
    "            try:  # 1-D array-like or int\n",
    "                ty = np.random.choice(self.width_shift_range)\n",
    "                ty *= np.random.choice([-1, 1])\n",
    "            except ValueError:  # floating point\n",
    "                ty = np.random.uniform(-self.width_shift_range,\n",
    "                                       self.width_shift_range)\n",
    "            if np.max(self.width_shift_range) < 1:\n",
    "                ty *= img_shape[img_col_axis]\n",
    "        else:\n",
    "            ty = 0\n",
    "\n",
    "        if self.shear_range:\n",
    "            shear = np.random.uniform(\n",
    "                -self.shear_range,\n",
    "                self.shear_range)\n",
    "        else:\n",
    "            shear = 0\n",
    "\n",
    "        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n",
    "            zx, zy = 1, 1\n",
    "        else:\n",
    "            zx, zy = np.random.uniform(\n",
    "                self.zoom_range[0],\n",
    "                self.zoom_range[1],\n",
    "                2)\n",
    "\n",
    "        flip_horizontal = (np.random.random() < 0.5) * self.horizontal_flip\n",
    "        flip_vertical = (np.random.random() < 0.5) * self.vertical_flip\n",
    "\n",
    "        channel_shift_intensity = None\n",
    "        if self.channel_shift_range != 0:\n",
    "            channel_shift_intensity = np.random.uniform(-self.channel_shift_range,\n",
    "                                                        self.channel_shift_range)\n",
    "\n",
    "        brightness = None\n",
    "        if self.brightness_range is not None:\n",
    "            brightness = np.random.uniform(self.brightness_range[0],\n",
    "                                           self.brightness_range[1])\n",
    "\n",
    "        transform_parameters = {'theta': theta,\n",
    "                                'tx': tx,\n",
    "                                'ty': ty,\n",
    "                                'shear': shear,\n",
    "                                'zx': zx,\n",
    "                                'zy': zy,\n",
    "                                'flip_horizontal': flip_horizontal,\n",
    "                                'flip_vertical': flip_vertical,\n",
    "                                'channel_shift_intensity': channel_shift_intensity,\n",
    "                                'brightness': brightness}\n",
    "\n",
    "        return transform_parameters\n",
    "\n",
    "    def apply_transform(self, x, transform_parameters):\n",
    "        \"\"\"Applies a transformation to an image according to given parameters.\n",
    "        # Arguments\n",
    "            x: 3D tensor, single image.\n",
    "            transform_parameters: Dictionary with string - parameter pairs\n",
    "                describing the transformation.\n",
    "                Currently, the following parameters\n",
    "                from the dictionary are used:\n",
    "                - `'theta'`: Float. Rotation angle in degrees.\n",
    "                - `'tx'`: Float. Shift in the x direction.\n",
    "                - `'ty'`: Float. Shift in the y direction.\n",
    "                - `'shear'`: Float. Shear angle in degrees.\n",
    "                - `'zx'`: Float. Zoom in the x direction.\n",
    "                - `'zy'`: Float. Zoom in the y direction.\n",
    "                - `'flip_horizontal'`: Boolean. Horizontal flip.\n",
    "                - `'flip_vertical'`: Boolean. Vertical flip.\n",
    "                - `'channel_shift_intensity'`: Float. Channel shift intensity.\n",
    "                - `'brightness'`: Float. Brightness shift intensity.\n",
    "        # Returns\n",
    "            A transformed version of the input (same shape).\n",
    "        \"\"\"\n",
    "        # x is a single image, so it doesn't have image number at index 0\n",
    "        img_row_axis = self.row_axis - 1\n",
    "        img_col_axis = self.col_axis - 1\n",
    "        img_channel_axis = self.channel_axis - 1\n",
    "\n",
    "        x = apply_affine_transform(x, transform_parameters.get('theta', 0),\n",
    "                                   transform_parameters.get('tx', 0),\n",
    "                                   transform_parameters.get('ty', 0),\n",
    "                                   transform_parameters.get('shear', 0),\n",
    "                                   transform_parameters.get('zx', 1),\n",
    "                                   transform_parameters.get('zy', 1),\n",
    "                                   row_axis=img_row_axis,\n",
    "                                   col_axis=img_col_axis,\n",
    "                                   channel_axis=img_channel_axis,\n",
    "                                   fill_mode=self.fill_mode,\n",
    "                                   cval=self.cval,\n",
    "                                   order=self.interpolation_order)\n",
    "\n",
    "        if transform_parameters.get('channel_shift_intensity') is not None:\n",
    "            x = apply_channel_shift(x,\n",
    "                                    transform_parameters['channel_shift_intensity'],\n",
    "                                    img_channel_axis)\n",
    "\n",
    "        if transform_parameters.get('flip_horizontal', False):\n",
    "            x = flip_axis(x, img_col_axis)\n",
    "\n",
    "        if transform_parameters.get('flip_vertical', False):\n",
    "            x = flip_axis(x, img_row_axis)\n",
    "\n",
    "        if transform_parameters.get('brightness') is not None:\n",
    "            x = apply_brightness_shift(x, transform_parameters['brightness'])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, x, seed=None):\n",
    "        \"\"\"Applies a random transformation to an image.\n",
    "        # Arguments\n",
    "            x: 3D tensor, single image.\n",
    "            seed: Random seed.\n",
    "        # Returns\n",
    "            A randomly transformed version of the input (same shape).\n",
    "        \"\"\"\n",
    "        params = self.get_random_transform(x.shape, seed)\n",
    "        return self.apply_transform(x, params)\n",
    "\n",
    "    def fit(self, x,\n",
    "            augment=False,\n",
    "            rounds=1,\n",
    "            seed=None):\n",
    "        \"\"\"Fits the data generator to some sample data.\n",
    "        This computes the internal data stats related to the\n",
    "        data-dependent transformations, based on an array of sample data.\n",
    "        Only required if `featurewise_center` or\n",
    "        `featurewise_std_normalization` or `zca_whitening` are set to True.\n",
    "        When `rescale` is set to a value, rescaling is applied to\n",
    "        sample data before computing the internal data stats.\n",
    "        # Arguments\n",
    "            x: Sample data. Should have rank 4.\n",
    "             In case of grayscale data,\n",
    "             the channels axis should have value 1, in case\n",
    "             of RGB data, it should have value 3, and in case\n",
    "             of RGBA data, it should have value 4.\n",
    "            augment: Boolean (default: False).\n",
    "                Whether to fit on randomly augmented samples.\n",
    "            rounds: Int (default: 1).\n",
    "                If using data augmentation (`augment=True`),\n",
    "                this is how many augmentation passes over the data to use.\n",
    "            seed: Int (default: None). Random seed.\n",
    "       \"\"\"\n",
    "        x = np.asarray(x, dtype=self.dtype)\n",
    "        if x.ndim != 4:\n",
    "            raise ValueError('Input to `.fit()` should have rank 4. '\n",
    "                             'Got array with shape: ' + str(x.shape))\n",
    "        if x.shape[self.channel_axis] not in {1, 3, 4}:\n",
    "            warnings.warn(\n",
    "                'Expected input to be images (as Numpy array) '\n",
    "                'following the data format convention \"' +\n",
    "                self.data_format + '\" (channels on axis ' +\n",
    "                str(self.channel_axis) + '), i.e. expected '\n",
    "                'either 1, 3 or 4 channels on axis ' +\n",
    "                str(self.channel_axis) + '. '\n",
    "                'However, it was passed an array with shape ' +\n",
    "                str(x.shape) + ' (' + str(x.shape[self.channel_axis]) +\n",
    "                ' channels).')\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        x = np.copy(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "\n",
    "        if augment:\n",
    "            ax = np.zeros(\n",
    "                tuple([rounds * x.shape[0]] + list(x.shape)[1:]),\n",
    "                dtype=self.dtype)\n",
    "            for r in range(rounds):\n",
    "                for i in range(x.shape[0]):\n",
    "                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n",
    "            x = ax\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n",
    "            self.mean = np.reshape(self.mean, broadcast_shape)\n",
    "            x -= self.mean\n",
    "\n",
    "        if self.featurewise_std_normalization:\n",
    "            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n",
    "            self.std = np.reshape(self.std, broadcast_shape)\n",
    "            x /= (self.std + 1e-6)\n",
    "\n",
    "        if self.zca_whitening:\n",
    "            if scipy is None:\n",
    "                raise ImportError('Using zca_whitening requires SciPy. '\n",
    "                                  'Install SciPy.')\n",
    "            flat_x = np.reshape(\n",
    "                x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n",
    "            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n",
    "            u, s, _ = linalg.svd(sigma)\n",
    "            s_inv = 1. / np.sqrt(s[np.newaxis] + self.zca_epsilon)\n",
    "            self.principal_components = (u * s_inv).dot(u.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='/data/DNNData/shared/COVID19Project/cxr_classification_consensus_normalized/all_data/'\n",
    "augm_dir='/data/DNNData/shared/COVID19Project/cxr_classification_consensus_normalized/all_data/augment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_datagen = ImageDataGenerator(validation_split=0.2, dtype='ushort')\n",
    "augmented_train_datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                             width_shift_range=0.1,\n",
    "                                             height_shift_range=0.1,\n",
    "                                             shear_range=0.1,\n",
    "                                             zoom_range=0.2,\n",
    "                                             horizontal_flip=False,\n",
    "                                             fill_mode='constant',\n",
    "                                             validation_split=0.2,\n",
    "                                             dtype='ushort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30163 images belonging to 3 classes.\n",
      "Found 7540 images belonging to 3 classes.\n",
      "Found 2252 images belonging to 3 classes.\n",
      "Found 563 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "input_shape=(1024,1024,3)\n",
    "\n",
    "original_train_generator = original_train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape[0:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['normal', 'mild', 'moderate-severe'], \n",
    "    shuffle=True, \n",
    "    subset='training',\n",
    "    color_mode='grayscale') \n",
    "\n",
    "original_val_generator = original_train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape[0:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['normal', 'mild', 'moderate-severe'], \n",
    "    shuffle=True,\n",
    "    subset='validation',\n",
    "    color_mode='grayscale') \n",
    "\n",
    "\n",
    "augmented_train_generator = augmented_train_datagen.flow_from_directory(\n",
    "    augm_dir,\n",
    "    target_size=input_shape[0:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['normal', 'mild', 'moderate-severe'],\n",
    "    shuffle=True,\n",
    "    subset='training',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "augmented_val_generator = augmented_train_datagen.flow_from_directory(\n",
    "    augm_dir,\n",
    "    target_size=input_shape[0:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=['normal', 'mild', 'moderate-severe'],\n",
    "    shuffle=True,\n",
    "    subset='validation',\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fill h5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_original_training = 30163\n",
    "num_original_validation = 7540\n",
    "\n",
    "num_tot_training = 30163 + 29276  # *13\n",
    "num_tot_validation = 7540 + 7319  # *13\n",
    "\n",
    "ff=h5py.File('/data/DNNData/shared/COVID19Project/cxr_classification_consensus_normalized/cxr_consensus_dataset.h5','w')\n",
    "\n",
    "args={}\n",
    "args['compression'] = 'gzip'\n",
    "args['compression_opts'] = 1\n",
    "\n",
    "X_train=ff.create_dataset(\"X_train\", (num_tot_training,) + input_shape, dtype='ushort', **args)\n",
    "y_train=ff.create_dataset(\"y_train\",(num_tot_training, 3),dtype='uint8', **args)\n",
    "\n",
    "X_val=ff.create_dataset(\"X_val\",(num_tot_validation,) + input_shape,dtype='ushort', **args)\n",
    "y_val=ff.create_dataset(\"y_val\",(num_tot_validation, 3),dtype='uint8', **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "100\n",
      "105\n",
      "110\n",
      "115\n",
      "120\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n",
      "160\n",
      "165\n",
      "170\n",
      "175\n",
      "180\n",
      "185\n",
      "190\n",
      "195\n",
      "200\n",
      "205\n",
      "210\n",
      "215\n",
      "220\n",
      "225\n",
      "230\n",
      "235\n",
      "240\n",
      "245\n",
      "250\n",
      "255\n",
      "260\n",
      "265\n",
      "270\n",
      "275\n",
      "280\n",
      "285\n",
      "290\n",
      "295\n",
      "300\n",
      "305\n",
      "310\n",
      "315\n",
      "320\n",
      "325\n",
      "330\n",
      "335\n",
      "340\n",
      "345\n",
      "350\n",
      "355\n",
      "360\n",
      "365\n",
      "370\n",
      "375\n",
      "380\n",
      "385\n",
      "390\n",
      "395\n",
      "400\n",
      "405\n",
      "410\n",
      "415\n",
      "420\n",
      "425\n",
      "430\n",
      "435\n",
      "440\n",
      "445\n",
      "450\n",
      "455\n",
      "460\n",
      "465\n",
      "470\n",
      "475\n",
      "480\n",
      "485\n",
      "490\n",
      "495\n",
      "500\n",
      "505\n",
      "510\n",
      "515\n",
      "520\n",
      "525\n",
      "530\n",
      "535\n",
      "540\n",
      "545\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for ii in range(0, num_original_training, batch_size):\n",
    "    print(ii)\n",
    "    _tmp=original_train_generator.next()\n",
    "    X_train[ii:ii+batch_size]=_tmp[0]\n",
    "    y_train[ii:ii+batch_size]=_tmp[1]\n",
    "for ii in range(num_original_training, num_tot_training, batch_size):\n",
    "    print(ii)\n",
    "    _tmp=augmented_train_generator.next()\n",
    "    X_train[ii:ii+batch_size]=_tmp[0]\n",
    "    y_train[ii:ii+batch_size]=_tmp[1]\n",
    "    \n",
    "# Validation\n",
    "for ii in range(0, num_original_validation, batch_size):\n",
    "    print(ii)\n",
    "    _tmp=original_val_generator.next()\n",
    "    X_val[ii:ii+batch_size]=_tmp[0]\n",
    "    y_val[ii:ii+batch_size]=_tmp[1]\n",
    "for ii in range(num_original_validation, num_tot_validation, batch_size):\n",
    "    print(ii)\n",
    "    _tmp=augmented_val_generator.next()\n",
    "    X_val[ii:ii+batch_size]=_tmp[0]\n",
    "    y_val[ii:ii+batch_size]=_tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from cip_python.dcnn.data import DataProcessing\n",
    "from cip_python.input_output import H5DatasetStore, Axis, ImageReaderWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_h5='/data/DNNData/shared/COVID19Project/cxr_classification_consensus/cxr_classification_consensus.h5'\n",
    "generator = H5DatasetStore(output_h5)\n",
    "generator.create_h5_file(description='Dataset containing XRays images (with consensus) for SlowdownCOVID19 projects',\n",
    "                         key_names=('cid',),\n",
    "                         keys_description=\"Element ids: case id (cid)\",\n",
    "                         override_if_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_original_training = 4290\n",
    "tot_num_training = 16000\n",
    "\n",
    "axes = [Axis.new_index(tot_num_training),\n",
    "        Axis(\"x_dim\", \"X image size\", 1024, Axis.TYPE_SPATIAL, Axis.UNIT_PIXEL),\n",
    "        Axis(\"y_dim\", \"Y image size\", 1024, Axis.TYPE_SPATIAL, Axis.UNIT_PIXEL),\n",
    "        Axis(\"c_dim\", \"Number of channels\", 3, Axis.TYPE_SPATIAL, Axis.UNIT_PIXEL)]\n",
    "\n",
    "generator.create_ndarray(name='XRays_images',\n",
    "                         general_description='XRays images',\n",
    "                         axes=axes, dtype=np.float32)\n",
    "generator.create_table(name='Pneumonia_level',\n",
    "                       general_description='Table containing categorical level of pneumonia (with consensus). [1.,0.,0.]=Normal, [0.,1.0.]=Mild, [0.,0.,1.]=Moderate-Severe',\n",
    "                       columns_names=(tuple(['Pneumonia Level'])),\n",
    "                       dtype=np.uint8,\n",
    "                       shape=(tot_num_training, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(num_original_training):\n",
    "    print(ii)\n",
    "    _tmp=original_train_generator.next()\n",
    "    generator.insert_ndarray_single_point(ds_name='XRays_images',\n",
    "                                          data_array=_tmp[0][0],\n",
    "                                          key_array=np.array(['cid']),\n",
    "                                          spacing_array=np.asarray((0.0, 0.0, 0.0)),\n",
    "                                          origin_array=np.asarray((0.0, 0.0, 0.0)),\n",
    "                                          missing=0)\n",
    "    \n",
    "    generator.insert_table_single_point(ds_name='Pneumonia_level',\n",
    "                                        data_array=_tmp[1][0],\n",
    "                                        key_array=np.array(['cid']))\n",
    "    \n",
    "for ii in range(num_original_training, tot_num_training):\n",
    "    print(ii)\n",
    "    _tmp=augmented_train_generator.next()\n",
    "    \n",
    "    generator.insert_ndarray_single_point(ds_name='XRays_images',\n",
    "                                          data_array=_tmp[0][0],\n",
    "                                          key_array=np.array(['cid']),\n",
    "                                          spacing_array=np.asarray([0.0, 0.0, 0.0]),\n",
    "                                          origin_array=np.asarray([0.0, 0.0, 0.0]),\n",
    "                                          missing=0)\n",
    "    \n",
    "    generator.insert_table_single_point(ds_name='Pneumonia_level',\n",
    "                                        data_array=_tmp[1][0],\n",
    "                                        key_array=np.array(['cid']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add train status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = H5DatasetStore(output_h5)\n",
    "cid = h5py.File(output_h5)['XRays_images.key'][:]\n",
    "\n",
    "# Add table containing the train status\n",
    "generator.create_table(name='train_status',\n",
    "                       general_description='Train status: 1=train, 2=validation, 3=test',\n",
    "                       columns_names=('train_status',), dtype=np.uint8,\n",
    "                       shape=(tot_num_training, 1))\n",
    "\n",
    "pp = np.random.permutation(tot_num_training)\n",
    "num_train_points = 12800\n",
    "num_val_points = 3200\n",
    "\n",
    "train_status_array = np.zeros((tot_num_training, 1), dtype=np.uint8)\n",
    "train_status_array[pp[0:num_train_points]] += 1\n",
    "train_status_array[pp[num_train_points:num_train_points + num_val_points]] += 2\n",
    "# train_status_array[pp[nb_train_images + nb_validation_images:]] += 3\n",
    "\n",
    "generator.insert_table_data_points('train_status', train_status_array, key_array=cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "import numpy as np\n",
    "from skimage import io, exposure, filters, img_as_uint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(img_in, clip_limit=0.01, med_filt=5,output_type='uint16', flag_draw=False):\n",
    "    if len(img_in.shape) == 3:\n",
    "        img = img_in[:, :, 0]\n",
    "    else:\n",
    "        img = img_in.copy()\n",
    "        \n",
    "    if img.dtype is np.dtype(np.float32):\n",
    "        img_norm = img / img.max()                                    # Format adaptation\n",
    "    else:\n",
    "        img_norm = img.astype('float32') / np.iinfo(img.dtype).max                  # Format adaptation\n",
    "    img_clahe = exposure.equalize_adapthist(img_norm, clip_limit=clip_limit)        # CLAHE\n",
    "    img_clahe_median = filters.median(img_clahe,np.ones((5,5))).astype('float32')   # Median Filter\n",
    "\n",
    "    lower, upper = np.percentile(img_clahe_median.flatten(), [2, 98])\n",
    "    img_clip = np.clip(img_clahe_median,lower, upper)\n",
    "    img_out = (img_clip - lower)/(upper - lower)\n",
    "\n",
    "    if output_type is not None:\n",
    "        max_val=np.iinfo(output_type).max\n",
    "        img_out=(max_val*img_out).astype(output_type)\n",
    "    else:\n",
    "        max_val=1.0\n",
    "\n",
    "    if flag_draw is True:\n",
    "        # plt.imshow(np.concatenate([img, img_clahe, img_clahe_median / img_clahe_median.max(), img_out],axis=1),cmap='gray')\n",
    "        plt.imshow(np.concatenate([max_val*img_norm, img_out],axis=1),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.figure(50)\n",
    "        plt.clf()\n",
    "        plt.hist(img_norm.flatten(), 256, alpha=0.2, density=True, label='original')\n",
    "        plt.hist(img_clahe.flatten(), 256, alpha=0.2, density=True, label='clahe')\n",
    "        plt.hist(img_out.flatten(),256, alpha=0.2, density=True, label='clahe_clip')\n",
    "        plt.legend()\n",
    "        plt.axis(xmin=0., xmax=1)\n",
    "        plt.show()\n",
    "    \n",
    "    if len(img_in.shape) == 3:\n",
    "        img_out = np.expand_dims(img_out, axis=-1)\n",
    "        img_out = np.tile(img_out, (1, 1, 3))\n",
    "        \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient16887_frontal.jpg\n",
      "patient13318_frontal.jpg\n",
      "patient11529_frontal.jpg\n",
      "patient47752_frontal.jpg\n",
      "patient33753_frontal.jpg\n",
      "patient06359_frontal.jpg\n",
      "patient19348_frontal.jpg\n",
      "patient14606_frontal.jpg\n",
      "patient21322_frontal.jpg\n",
      "patient07820_frontal.jpg\n",
      "patient33890_frontal.jpg\n",
      "patient16735_frontal.jpg\n",
      "patient27627_frontal.jpg\n",
      "patient46781_frontal.jpg\n",
      "patient19655_frontal.jpg\n",
      "patient27591_frontal.jpg\n",
      "patient21316_frontal.jpg\n",
      "patient56539_frontal.jpg\n",
      "patient37340_frontal.jpg\n",
      "patient57561_frontal.jpg\n",
      "patient25094_frontal.jpg\n",
      "patient29961_frontal.jpg\n",
      "patient62632_frontal.jpg\n",
      "patient17971_frontal.jpg\n",
      "patient36758_frontal.jpg\n",
      "patient06592_frontal.jpg\n",
      "patient40518_frontal.jpg\n",
      "patient21910_frontal.jpg\n",
      "patient26116_frontal.jpg\n",
      "patient49985_frontal.jpg\n",
      "patient31472_frontal.jpg\n",
      "patient20786_frontal.jpg\n",
      "patient61461_frontal.jpg\n",
      "patient17227_frontal.jpg\n",
      "patient54730_frontal.jpg\n",
      "patient44326_frontal.jpg\n",
      "patient48320_frontal.jpg\n",
      "patient37912_frontal.jpg\n",
      "patient40837_frontal.jpg\n",
      "patient17437_frontal.jpg\n",
      "patient01694_frontal.jpg\n",
      "patient35055_frontal.jpg\n",
      "patient58168_frontal.jpg\n",
      "patient13264_frontal.jpg\n",
      "patient06212_frontal.jpg\n",
      "patient37256_frontal.jpg\n",
      "patient05026_frontal.jpg\n",
      "patient08146_frontal.jpg\n",
      "patient36973_frontal.jpg\n",
      "patient53492_frontal.jpg\n",
      "patient29298_frontal.jpg\n",
      "patient30107_frontal.jpg\n",
      "patient19591_frontal.jpg\n",
      "patient09030_frontal.jpg\n",
      "patient40939_frontal.jpg\n",
      "patient28941_frontal.jpg\n",
      "patient24546_frontal.jpg\n",
      "patient02146_frontal.jpg\n",
      "patient50243_frontal.jpg\n",
      "patient09443_frontal.jpg\n",
      "patient18170_frontal.jpg\n",
      "patient15512_frontal.jpg\n",
      "patient26616_frontal.jpg\n",
      "patient09292_frontal.jpg\n",
      "patient42973_frontal.jpg\n",
      "patient29767_frontal.jpg\n",
      "patient32706_frontal.jpg\n",
      "patient23960_frontal.jpg\n",
      "patient05946_frontal.jpg\n",
      "patient03129_frontal.jpg\n",
      "patient22183_frontal.jpg\n",
      "patient14312_frontal.jpg\n",
      "patient48714_frontal.jpg\n",
      "patient38177_frontal.jpg\n",
      "patient10706_frontal.jpg\n",
      "patient11504_frontal.jpg\n",
      "patient30393_frontal.jpg\n",
      "patient22298_frontal.jpg\n",
      "patient16266_frontal.jpg\n",
      "patient11923_frontal.jpg\n",
      "patient48909_frontal.jpg\n",
      "patient20486_frontal.jpg\n",
      "patient11828_frontal.jpg\n",
      "patient19361_frontal.jpg\n",
      "patient49341_frontal.jpg\n",
      "patient17284_frontal.jpg\n",
      "patient54707_frontal.jpg\n",
      "patient09836_frontal.jpg\n",
      "patient26034_frontal.jpg\n",
      "patient23700_frontal.jpg\n",
      "patient08264_frontal.jpg\n",
      "patient42417_frontal.jpg\n",
      "patient63096_frontal.jpg\n",
      "patient08188_frontal.jpg\n",
      "patient57654_frontal.jpg\n",
      "patient05208_frontal.jpg\n",
      "patient15623_frontal.jpg\n",
      "patient22457_frontal.jpg\n",
      "patient18694_frontal.jpg\n",
      "patient39730_frontal.jpg\n",
      "patient12175_frontal.jpg\n",
      "patient35086_frontal.jpg\n",
      "patient45184_frontal.jpg\n",
      "patient42493_frontal.jpg\n",
      "patient06115_frontal.jpg\n",
      "patient04449_frontal.jpg\n",
      "patient58599_frontal.jpg\n",
      "patient26036_frontal.jpg\n",
      "patient16055_frontal.jpg\n",
      "patient41677_frontal.jpg\n",
      "patient46614_frontal.jpg\n",
      "patient50131_frontal.jpg\n",
      "patient19777_frontal.jpg\n",
      "patient56558_frontal.jpg\n",
      "patient07824_frontal.jpg\n",
      "patient30635_frontal.jpg\n",
      "patient22953_frontal.jpg\n",
      "patient48037_frontal.jpg\n",
      "patient36083_frontal.jpg\n",
      "patient14882_frontal.jpg\n",
      "patient33588_frontal.jpg\n",
      "patient30241_frontal.jpg\n",
      "patient17675_frontal.jpg\n",
      "patient43546_frontal.jpg\n",
      "patient38503_frontal.jpg\n",
      "patient17131_frontal.jpg\n",
      "patient36820_frontal.jpg\n",
      "patient30374_frontal.jpg\n",
      "patient07905_frontal.jpg\n",
      "patient29319_frontal.jpg\n",
      "patient19006_frontal.jpg\n",
      "patient02779_frontal.jpg\n",
      "patient28399_frontal.jpg\n",
      "patient44981_frontal.jpg\n",
      "patient08016_frontal.jpg\n",
      "patient53409_frontal.jpg\n",
      "patient18167_frontal.jpg\n",
      "patient06877_frontal.jpg\n",
      "patient11136_frontal.jpg\n",
      "patient01441_frontal.jpg\n",
      "patient05771_frontal.jpg\n",
      "patient09733_frontal.jpg\n",
      "patient10302_frontal.jpg\n",
      "patient35073_frontal.jpg\n",
      "patient05824_frontal.jpg\n",
      "patient17795_frontal.jpg\n",
      "patient06578_frontal.jpg\n",
      "patient22822_frontal.jpg\n",
      "patient39965_frontal.jpg\n",
      "patient31049_frontal.jpg\n",
      "patient39782_frontal.jpg\n",
      "patient39060_frontal.jpg\n",
      "patient27774_frontal.jpg\n",
      "patient42864_frontal.jpg\n",
      "patient51029_frontal.jpg\n",
      "patient08250_frontal.jpg\n",
      "patient29331_frontal.jpg\n",
      "patient47815_frontal.jpg\n",
      "patient46834_frontal.jpg\n",
      "patient11260_frontal.jpg\n",
      "patient20889_frontal.jpg\n",
      "patient10684_frontal.jpg\n",
      "patient37942_frontal.jpg\n",
      "patient21149_frontal.jpg\n",
      "patient07757_frontal.jpg\n",
      "patient59107_frontal.jpg\n",
      "patient51641_frontal.jpg\n",
      "patient58299_frontal.jpg\n",
      "patient26376_frontal.jpg\n",
      "patient21924_frontal.jpg\n",
      "patient11573_frontal.jpg\n",
      "patient16839_frontal.jpg\n",
      "patient04860_frontal.jpg\n",
      "patient41283_frontal.jpg\n",
      "patient38667_frontal.jpg\n",
      "patient13099_frontal.jpg\n",
      "patient00086_frontal.jpg\n",
      "patient48092_frontal.jpg\n",
      "patient16501_frontal.jpg\n",
      "patient11586_frontal.jpg\n",
      "patient11631_frontal.jpg\n",
      "patient40453_frontal.jpg\n",
      "patient27547_frontal.jpg\n",
      "patient06711_frontal.jpg\n",
      "patient32618_frontal.jpg\n",
      "patient10897_frontal.jpg\n",
      "patient59550_frontal.jpg\n",
      "patient48346_frontal.jpg\n",
      "patient25476_frontal.jpg\n",
      "patient16619_frontal.jpg\n",
      "patient44833_frontal.jpg\n",
      "patient07867_frontal.jpg\n",
      "patient19744_frontal.jpg\n",
      "patient18743_frontal.jpg\n",
      "patient39157_frontal.jpg\n",
      "patient38857_frontal.jpg\n",
      "patient04317_frontal.jpg\n",
      "patient19471_frontal.jpg\n",
      "patient54294_frontal.jpg\n",
      "patient01110_frontal.jpg\n",
      "patient45938_frontal.jpg\n",
      "patient13513_frontal.jpg\n",
      "patient04346_frontal.jpg\n",
      "patient63661_frontal.jpg\n",
      "patient04328_frontal.jpg\n"
     ]
    }
   ],
   "source": [
    "basedir='/data/DNNData/shared/COVID19Project/cxr_classification_consensus/COVID_project/'\n",
    "out_basedir='/data/DNNData/shared/COVID19Project/cxr_classification_consensus_normalized/'\n",
    "# input_dir_names = [basedir+'CheXpert/mild/', basedir+'CheXpert/moderate-severe/', \n",
    "#                    basedir+'NIHDeepLesion/mild/', basedir+'NIHDeepLesion/moderate-severe/',\n",
    "#                    basedir+'PADCHEST/mild/', basedir+'PADCHEST/moderate-severe/']\n",
    "# output_dir_names = [out_basedir+'CheXpert/mild/', out_basedir+'CheXpert/moderate-severe/', \n",
    "#                     out_basedir+'NIHDeepLesion/mild/', out_basedir+'NIHDeepLesion/moderate-severe/',\n",
    "#                     out_basedir+'PADCHEST/mild/', out_basedir+'PADCHEST/moderate-severe/']\n",
    "\n",
    "input_dir_names = [basedir+'CheXpert/moderate-severe/']\n",
    "output_dir_names = [out_basedir+'CheXpert/moderate-severe/']\n",
    "\n",
    "for ii, oo in zip(input_dir_names, output_dir_names):\n",
    "    cxr_in_files = [join(ii, f) for f in listdir(ii) if isfile(join(ii, f))]\n",
    "    for ff in cxr_in_files[395:600]:\n",
    "        img_name = ff.split('/')[-1]\n",
    "        print(img_name)\n",
    "        img = image.imread(ff)\n",
    "        img2 = equalize(img, flag_draw=False, output_type='uint16')\n",
    "        img_format = img_name.split('.')[-1]\n",
    "        output_file = oo + img_name.split('.')[0] + '.png'\n",
    "#         image.imsave(output_file, img2, format=img_format, cmap='gray')\n",
    "        io.imsave(output_file, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
